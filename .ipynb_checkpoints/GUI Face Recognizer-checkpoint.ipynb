{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbecbb89-5cb4-43c4-b9e6-8784d5febbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import cv2\n",
    "import os \n",
    "from PIL import Image \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1aa12677-c7dc-4d48-b9d7-29f995ee0208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:59: SyntaxWarning: \"is\" with 'tuple' literal. Did you mean \"==\"?\n",
      "<>:59: SyntaxWarning: \"is\" with 'tuple' literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'detect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m b1 \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mButton(window, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, font\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlgerian\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m20\u001b[39m),bg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m\"\u001b[39m,fg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,command\u001b[38;5;241m=\u001b[39mtrain_classifier)\n\u001b[0;32m     43\u001b[0m b1\u001b[38;5;241m.\u001b[39mgrid(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, row\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m b2 \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mButton(window, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetect the faces\u001b[39m\u001b[38;5;124m\"\u001b[39m, font\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlgerian\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m20\u001b[39m), bg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m, fg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m\"\u001b[39m,command\u001b[38;5;241m=\u001b[39mdetect)\n\u001b[0;32m     46\u001b[0m b2\u001b[38;5;241m.\u001b[39mgrid(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, row\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_dataset\u001b[39m():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'detect' is not defined"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    " \n",
    "window = tk.Tk()\n",
    "window.title(\"Face Recognition system\")\n",
    " \n",
    "l1 = tk.Label(window, text=\"Name\", font=(\"Algerian\",20))\n",
    "l1.grid(column=0, row=0)\n",
    "t1 = tk.Entry(window, width=50, bd=5)\n",
    "t1.grid(column=1, row=0)\n",
    " \n",
    "l2 = tk.Label(window, text=\"Age\", font=(\"Algerian\",20))\n",
    "l2.grid(column=0, row=1)\n",
    "t2 = tk.Entry(window, width=50, bd=5)\n",
    "t2.grid(column=1, row=1)\n",
    " \n",
    "l3 = tk.Label(window, text=\"Address\", font=(\"Algerian\",20))\n",
    "l3.grid(column=0, row=2)\n",
    "t3 = tk.Entry(window, width=50, bd=5)\n",
    "t3.grid(column=1, row=2)\n",
    "\n",
    "def train_classifier():\n",
    "    data_dir=\"C:/Users/dixit/Face Recognition/data\"\n",
    "    path = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\n",
    "    faces = []\n",
    "    ids = []\n",
    "    for image in path:\n",
    "        img = Image.open(image).convert('L')\n",
    "        imageNp = np.array(img, 'uint8')\n",
    "        id = int(os.path.split(image)[1].split(\".\")[1])\n",
    "        faces.append(imageNp)\n",
    "        ids.append(id)\n",
    "    ids = np.array(ids)\n",
    "    # Train the Classifier and Save\n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clf.train(faces, ids)\n",
    "    clf.write(\"classifier.xml\")\n",
    "    messagebox.showinfo('Result','Training Dataset Completed!!!')\n",
    "\n",
    "    train_classifier(\"data\")\n",
    " \n",
    "b1 = tk.Button(window, text=\"Training\", font=(\"Algerian\",20),bg=\"orange\",fg=\"red\",command=train_classifier)\n",
    "b1.grid(column=0, row=4)\n",
    "\n",
    "def detect_face():\n",
    "\n",
    "b2 = tk.Button(window, text=\"Detect the faces\", font=(\"Algerian\",20), bg=\"green\", fg=\"orange\",command=detect_face)\n",
    "b2.grid(column=1, row=4)\n",
    "\n",
    "def generate_dataset():\n",
    "    if(t1.get()==\"\" or t2.get()==\"\" or t3.get()==\"\"):\n",
    "        messagebox.showinfo('Result','Please Provide Complete details of the user')\n",
    "    else:\n",
    "        face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "        def face_cropped(img):\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "            #scaling factor=1.3\n",
    "            #Minimum neighbour = 5\n",
    "    \n",
    "            if faces is ():\n",
    "                return None\n",
    "            for(x,y,w,h) in faces:\n",
    "                cropped_face=img[y:y+h,x:x+w]\n",
    "            return cropped_face\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        id=1\n",
    "        img_id=0\n",
    "    \n",
    "        while True:\n",
    "            ret,frame = cap.read()\n",
    "            if face_cropped(frame) is not None:\n",
    "                img_id+=1\n",
    "                face = cv2.resize(face_cropped(frame),(200,200))\n",
    "                face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "                file_name_path = \"C:/Users/dixit/Face Recognition/data/user.\"+str(id)+\".\"+str(img_id)+\".jpg\"\n",
    "                cv2.imwrite(file_name_path,face)\n",
    "                cv2.putText(face,str(img_id),(50,50),cv2.FONT_HERSHEY_COMPLEX,1, (0,255,0),2)\n",
    "                #(50,50) is the origin point from where the  text is to be written\n",
    "                #font scale = 1\n",
    "                #thickness = 2\n",
    "    \n",
    "                cv2.imshow(\"Cropped face\",face)\n",
    "                if cv2.waitKey(1)==13 or int(img_id)==200:\n",
    "                    break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        messagebox.showinfo('Result','Generating Dataset Completed!!!')\n",
    "\n",
    "b3 = tk.Button(window, text=\"Generate dataset\", font=(\"Algerian\",20), bg=\"pink\", fg=\"black\",command=generate_dataset)\n",
    "b3.grid(column=2, row=4)\n",
    " \n",
    "window.geometry(\"800x200\")\n",
    "window.mainloop()\n",
    " \n",
    "#other just copy code from previous part same like as I have done in this video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a89286-15ce-4ba7-9b77-905f951d256d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
